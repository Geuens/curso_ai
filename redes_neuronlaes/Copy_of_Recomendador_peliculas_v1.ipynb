{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geuens/curso_ai/blob/main/Copy_of_Recomendador_peliculas_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F2aQklSEOUqv",
        "outputId": "72d459ac-9889-4ff3-f41d-bf8630f332d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.8.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.14)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.35.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://86c8eaafb056ecbd3b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://86c8eaafb056ecbd3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install gradio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "import pickle\n",
        "# NLTK Stem y stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def explore_data(movies):\n",
        "\n",
        "    # Exploración inicial de los datos\n",
        "    median_average = movies['vote_average'].median()\n",
        "    median_count = movies['vote_count'].median()\n",
        "    # print(median_average, median_count)\n",
        "    percentil = movies['vote_count'].quantile(0.8)\n",
        "    # print(percentil)\n",
        "    # print(\"Número de peliculas dentro del percentil: \" + str(len(movies[movies['vote_count']>percentil])))\n",
        "\n",
        "    d_movies = movies.copy().loc[movies['vote_count'] > percentil]\n",
        "    registros, columnas = d_movies.shape\n",
        "    # print(\"registros: \" + str(registros) + \" Columnas: \" + str(columnas))\n",
        "\n",
        "    # Podemos hacer una visualización de cómo se distribuyen los votos con nuestro percentil\n",
        "\n",
        "    # Con Seaborn\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x='vote_count', y='vote_average', data=d_movies)\n",
        "    plt.title('Distribución de Promedio de Votos')\n",
        "    plt.xlabel('Conteo')\n",
        "    plt.ylabel('Promedio de Votos')\n",
        "    plt.show()\n",
        "\n",
        "    # Podemos hacer una visualización de las películas con mayor índice de popularidad\n",
        "    populares = d_movies.sort_values('popularity', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12,4))\n",
        "\n",
        "    plt.barh(populares['title'].head(6),populares['popularity'].head(6), align='center', color='skyblue')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xlabel(\"Popularidad\")\n",
        "    plt.title(\"Películas Populares\")\n",
        "    plt.show()\n",
        "\n",
        "# El índice bayes, que se utiliza en el sistema Imbd, nos permite equilibrar las valoraciones con el número de votos\n",
        "# v es el número de votos por película (vote_count).\n",
        "# m es el umbral mínimo de votos en nuestro caso el percentil 0.8.\n",
        "# R es la calificación promedio de la película (vote_average).\n",
        "# C es el promedio de votos general. d_movies['vote_average'].mean()\n",
        "def rating_ponderado(data, percentil, C):\n",
        "    v = data['vote_count']\n",
        "    R = data['vote_average']\n",
        "    return (v/(v+percentil) * R) + (percentil/(percentil+v) * C)\n",
        "\n",
        "# Mostramos las primeras 10 con la columnas\n",
        "#print(movies[['title','score', 'vote_count', 'vote_average']].head(10))\n",
        "\n",
        "# print(movies['overview'].head(5))\n",
        "\n",
        "# Proceso de stemización. Puede no ser necesario pero reduce la dimensionalidad y es una forma de normalización\n",
        "def preprocess(text):\n",
        "\n",
        "    # Preparamos stemmer y stopwords\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Tokenizar el texto\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Eliminar stopwords y aplicar stemming\n",
        "    return ' '.join([stemmer.stem(word) for word in words if word.lower() not in stop_words and word.isalpha()])\n",
        "\n",
        "def load_data():\n",
        "    # Carga del dataset de créditos\n",
        "    credits = pd.read_csv('drive/MyDrive/Colab Notebooks/data/TMDB_5000_Movie/tmdb_5000_credits.csv')\n",
        "\n",
        "    # Carga del dataset de películas\n",
        "    movies = pd.read_csv('drive/MyDrive/Colab Notebooks/data/TMDB_5000_Movie/tmdb_5000_movies.csv')\n",
        "\n",
        "    # Carga del dataset de equivalencias entre imdb y tmdb\n",
        "    links = pd.read_csv('drive/MyDrive/Colab Notebooks/data/TMDB_5000_Movie/links.csv')\n",
        "    links.drop('movieId', axis=1, inplace=True)\n",
        "\n",
        "    movies = movies.merge(links, left_on='id', right_on='tmdbId', how='left')\n",
        "    movies.drop('tmdbId', axis=1, inplace=True)\n",
        "\n",
        "    credits.columns = ['id', 'title', 'cast', 'crew']\n",
        "    credits.drop(['title'], axis=1, inplace=True)\n",
        "    movies= movies.merge(credits,on='id')\n",
        "    # Con fillna ponemos strings vacias en NaN. apply pasamos la función sobre cada overview\n",
        "    movies['overview'] = movies['overview'].fillna('').apply(preprocess)\n",
        "    ####Descartamos crew ya que no nos aporta y descargamos peso\n",
        "\n",
        "    movies.drop('crew', axis=1, inplace=True)\n",
        "\n",
        "    # Convert the string representation to a list of dictionaries\n",
        "    movies['cast'] = movies['cast'].apply(lambda x: json.loads(x))\n",
        "\n",
        "    # Extract the \"name\" values from the list of dictionaries\n",
        "    movies['cast'] = movies['cast'].apply(lambda x: [actor['name'] for actor in x])\n",
        "    movies['cast'] = movies['cast'].apply(lambda x: \",\".join(x))\n",
        "\n",
        "    # Convert the string representation to a list of dictionaries\n",
        "    movies['genres'] = movies['genres'].apply(lambda x: json.loads(x))\n",
        "\n",
        "    # Extract the \"name\" values from the list of dictionaries\n",
        "    movies['genres'] = movies['genres'].apply(lambda x: [genre['name'] for genre in x])\n",
        "    movies['genres'] = movies['genres'].apply(lambda x: \",\".join(x))\n",
        "\n",
        "    # Convert the string representation to a list of dictionaries\n",
        "    movies['keywords'] = movies['keywords'].apply(lambda x: json.loads(x))\n",
        "\n",
        "    # Extract the \"name\" values from the list of dictionaries\n",
        "    movies['keywords'] = movies['keywords'].apply(lambda x: [keyword['name'] for keyword in x])\n",
        "    movies['keywords'] = movies['keywords'].apply(lambda x: \",\".join(x))\n",
        "\n",
        "\n",
        "    # Combine the text from \"cast,\" \"genres,\" and \"keywords\" columns into a single text column\n",
        "    movies['combined_text'] = movies['overview'] + ' ' + movies['cast'] + ' ' + movies['genres'] + ' ' + movies['keywords']\n",
        "\n",
        "    # Promedios de votos lo vamos a necesitar para calcula indice bayes.\n",
        "    C = movies['vote_average'].mean()\n",
        "    # Agregamos a movies el campo score que nos servirá para ordenar los resultados\n",
        "    # y ofrecer los mejor valorados primero. d_movies es nuestro dataframe con percentil\n",
        "    percentil = movies['vote_count'].quantile(0.8)\n",
        "    movies['score'] = movies.apply(rating_ponderado, axis=1, args=(percentil, C))\n",
        "    #Ordenar película en descendente por score\n",
        "\n",
        "    return movies\n",
        "\n",
        "def simple_recommendator(movies, reference_movie_index):\n",
        "    ################################# Calculo de el grado de similitud usando TF-IDF y https://es.wikipedia.org/wiki/Similitud_coseno ##########################################\n",
        "\n",
        "    #Podemos hacer las stopwords de una vez con tfidfVectotizer, pero antes hemos usado NLTK\n",
        "    #tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    # Initialize the TF-IDF vectorizer\n",
        "    tfidf = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the preprocessed overviews\n",
        "    tfidf_matrix = tfidf.fit_transform(movies['overview'])\n",
        "\n",
        "    # Calculate the cosine similarity matrix\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    #ordenamos las pelicula según indice\n",
        "    movies = movies.sort_index()\n",
        "    #Output the shape of tfidf_matrix\n",
        "    # print(tfidf_matrix.shape)\n",
        "\n",
        "    # Calculate cosine similarity with all movies\n",
        "    cosine_sim_scores = cosine_similarity(tfidf_matrix[reference_movie_index], tfidf_matrix)\n",
        "\n",
        "    # Get the indices of movies with highest similarity (excluding the reference movie)\n",
        "    similar_movie_indices = cosine_sim_scores.argsort()[0][::-1][1:]\n",
        "\n",
        "    # Get the top N similar movies\n",
        "    top_N = 10  # Change this to the desired number of recommendations\n",
        "    recommended_movies = movies.iloc[similar_movie_indices[:top_N]]\n",
        "    return recommended_movies # 'recommended_movies' now contains the top N recommended movies based on cosine similarity.\n",
        "\n",
        "# Ahora se alinean mucho mnejor las recomendaciones con la película avatar!!\n",
        "#print(recommended_movies.sort_values('score', ascending=False)['title'])\n",
        "\n",
        "def save_to_excel(movies):\n",
        "    # Save the dataset to an Excel file\n",
        "    movies.to_excel('excel_movies.xlsx', index=True)\n",
        "\n",
        "\n",
        "movies = load_data()\n",
        "\n",
        "def train_recommendation():\n",
        "\n",
        "    # Create a TF-IDF vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the combined text column\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(movies['combined_text'])\n",
        "\n",
        "    save_recomendation(tfidf_matrix)\n",
        "    return tfidf_matrix\n",
        "\n",
        "def save_recomendation(tfidf_matrix):\n",
        "    with open('tfidf_matrix.pickle', 'wb') as handle:\n",
        "        pickle.dump(tfidf_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_tfidf_matrix():\n",
        "\n",
        "    with open('tfidf_matrix.pickle', 'rb') as handle:\n",
        "        tfidf_matrix = pickle.load(handle)\n",
        "    return tfidf_matrix\n",
        "\n",
        "def recommendation(reference_movie_index):\n",
        "    # Si existe el fichero con la matriz lo cargamos, si no llamamos a train_recommendation\n",
        "    try:\n",
        "        tfidf_matrix = load_tfidf_matrix()\n",
        "    except:\n",
        "        tfidf_matrix = train_recommendation()\n",
        "\n",
        "    cosine_sim_scores = cosine_similarity(tfidf_matrix[reference_movie_index], tfidf_matrix)\n",
        "\n",
        "    # Get the indices of movies with highest similarity (excluding the reference movie)\n",
        "    similar_movie_indices = cosine_sim_scores.argsort()[0][::-1][1:]\n",
        "\n",
        "    # Get the top N similar movies\n",
        "    top_N = 10  # Change this to the desired number of recommendations\n",
        "    recommended_movies = movies.iloc[similar_movie_indices[:top_N]]\n",
        "    print(recommended_movies.columns)\n",
        "    return recommended_movies['title']\n",
        "#print(recommendation(0)['title'])\n",
        "\n",
        "# Crea una lista de diccionarios para el dropdown\n",
        "movie_options = [(row[\"title\"], index) for index, row in movies.iterrows()]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    recommendation,\n",
        "    [\n",
        "\n",
        "        gr.Dropdown(\n",
        "            movie_options, label=\"Película\", info=\"Selecciona una película que te haya gustado\"\n",
        "        ),\n",
        "\n",
        "    ],\n",
        "    \"text\"\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch()"
      ]
    }
  ]
}